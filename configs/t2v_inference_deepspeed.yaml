TASK_TYPE: inference_t2v_deepspeed
ENABLE: False
use_ema: False
num_workers: 16


max_frames: 16
sample_fps: 3
resolution: [256,256]

## deoning batch size
batch_size: 16

decoder_bs: 16

inference_seed: 42

model_name: "DEMO"


# For MSRVTT
infer_dataset: {
    'type': 'InferenceDatasetMSRVTT',
    'json_path': 'PATH_TO_MSRVTT_JSON',
    'repeat_times': 1,
}


# # For MSVD
# infer_dataset: {
#     'type': 'InferenceDatasetMSVD',
#     'json_path': 'PATH_TO_MSVD_JSON',
#     'repeat_times': 1,
# }

# # For WebVid
# infer_dataset: {
#     'type': 'InferenceDatasetWebVid',
#     'csv_path': 'PATH_TO_WEBVID_CSV',
#     'repeat_times': 1,
# }

# # For UCF101
# infer_dataset: {
#     'type': 'InferenceDatasetUCF101',
#     'csv_path': 'PATH_TO_UCF101_CSV',
#     'repeat_times': 1,
# }

# # For VBench
# infer_dataset: {
#     'type': 'InferenceDatasetVBench',
#     'json_path': 'PATH_TO_VBENCH_JSON',
#     'repeat_times': 5,
# }

# # For EvalCrafter
# infer_dataset: {
#     'type': 'InferenceDatasetEvalCrafter',
#     'csv_path': 'PATH_TO_EVALCRAFTER_CSV',
#     'repeat_times': 1,
# }

embedder: {
    'type': 'FrozenOpenCLIPEmbedder',
    'layer': 'penultimate',
    'pretrained': 'models/modelscopet2v/open_clip_pytorch_model.bin',
    'freeze': True
}

motion_encoder: {
    'type': 'MotionEncoder',
    'layer': 'penultimate',
    'pretrained': 'PATH_TO_MOTION_ENCODER',  # Path to .pth checkpoint file
    'freeze': True,
    'from_incomplete': True,
}

Pretrain: {
    'type': load_model,
    'from_modelscope': False,
    'inference': True,
    'resume_checkpoint': 'PATH_TO_PRETRAINED_MODEL',  # Path to .pth checkpoint file
}



UNet: {
    'type': 'UNetSD_T2V_DEMO',
    'in_dim': 4,
    'y_dim': 1024,
    'upper_len': 128,
    'context_dim': 1024,
    'out_dim': 4,
    'dim_mult': [1, 2, 4, 4],
    'num_heads': 8,
    'default_fps': 8,
    'head_dim': 64,
    'num_res_blocks': 2,
    'dropout': 0.1,
    'misc_dropout': 0.4,
    'temporal_attention': True,
    'temporal_attn_times': 1,
    'use_checkpoint': True,
    'use_fps_condition': False,
    'use_sim_mask': False,
    'text_reweight': True,
}



Diffusion: {
    'type': 'DiffusionDDIM',
    'schedule': 'linear_sd', # cosine
    'schedule_param': {
        'num_timesteps': 1000,
        'init_beta': 0.00085,
        'last_beta': 0.0120,
        'zero_terminal_snr': False,
    },
    'mean_type': 'eps',
    'loss_type': 'mse',
    'var_type': 'fixed_small',
    'rescale_timesteps': False,
    'noise_strength': 0.0000
}



guide_scale: 5.5

## vqa encode&decode scale
scale: 8

# Log
log_dir: "PATH_TO_SAVE_GENERATED_VIDEOS" 




mean: [0.5, 0.5, 0.5]
std: [0.5, 0.5, 0.5]
max_words: 1000

prefetch_factor: 1
ddim_timesteps: 50  # official: 250
use_div_loss: False

# Model
scale_factor: 0.18215  
use_fsdp: False 
use_fp16: True
temporal_attention: True



auto_encoder: {
    'type': 'AutoencoderKL',
    'ddconfig': {
        'double_z': True, 
        'z_channels': 4,
        'resolution': 256, 
        'in_channels': 3,
        'out_ch': 3, 
        'ch': 128, 
        'ch_mult': [1, 2, 4, 4],
        'num_res_blocks': 2, 
        'attn_resolutions': [], 
        'dropout': 0.0,
        'video_kernel_size': [3, 1, 1]
    },
    'embed_dim': 4,
    'pretrained': 'models/modelscopet2v/VQGAN_autoencoder.pth'
}

negative_prompt: 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms'


deepspeed_config: "ds_configs/ds_config_inference.json"